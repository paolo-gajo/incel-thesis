{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"sample_n_list = [5_000, 10_000, 50_000, 100_000, 500_000, 1_000_000]\nsample_n = sample_n_list[4]\nprint(sample_n)\nlanguage_option_list = ['english', 'italian', 'multi']\nlanguage_option = language_option_list[2]\nprint(language_option)","metadata":{"execution":{"iopub.status.busy":"2023-03-27T21:44:46.068022Z","iopub.execute_input":"2023-03-27T21:44:46.068892Z","iopub.status.idle":"2023-03-27T21:44:46.106354Z","shell.execute_reply.started":"2023-03-27T21:44:46.068843Z","shell.execute_reply":"2023-03-27T21:44:46.105171Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"500000\nmulti\n","output_type":"stream"}]},{"cell_type":"code","source":"# monolingual\n# model_name = 'bert-base-uncased'\n# model_name = 'roberta-base'\n\n# multilingual\nmodel_name = 'bert-base-multilingual-cased'\n# model_name = 'xlm-roberta-base'","metadata":{"execution":{"iopub.status.busy":"2023-03-27T21:44:46.108484Z","iopub.execute_input":"2023-03-27T21:44:46.109424Z","iopub.status.idle":"2023-03-27T21:44:46.114530Z","shell.execute_reply.started":"2023-03-27T21:44:46.109381Z","shell.execute_reply":"2023-03-27T21:44:46.113329Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Replace these with the appropriate model and tokenizer names\nnew_model_name = 'incel-'+model_name+'-'+str(int(sample_n/1000))+'k_'+language_option\n\n# Save the model and tokenizer to a directory\noutput_dir = \"/kaggle/working/\"\n\nimport os\n# Create the directory if it doesn't exist\nmodel_path = os.path.join(output_dir,new_model_name)\n\nif not os.path.exists(model_path):\n    os.makedirs(model_path)\nmodel_path","metadata":{"execution":{"iopub.status.busy":"2023-03-27T21:44:46.116462Z","iopub.execute_input":"2023-03-27T21:44:46.116908Z","iopub.status.idle":"2023-03-27T21:44:46.129202Z","shell.execute_reply.started":"2023-03-27T21:44:46.116871Z","shell.execute_reply":"2023-03-27T21:44:46.127838Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/incel-bert-base-multilingual-cased-500k_multi'"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nfrom datasets import Dataset\nfrom transformers import BertTokenizer, BertForMaskedLM, DataCollatorForLanguageModeling, AutoTokenizer, AutoModelForMaskedLM, Trainer, TrainingArguments\nimport pickle\nfrom typing import Dict\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{"id":"FpGqTHp1qoLC","outputId":"a4796bda-5c20-491f-effd-9f80d9d7964c","execution":{"iopub.status.busy":"2023-03-26T21:04:55.681525Z","iopub.execute_input":"2023-03-26T21:04:55.682050Z","iopub.status.idle":"2023-03-26T21:05:05.264093Z","shell.execute_reply.started":"2023-03-26T21:04:55.682014Z","shell.execute_reply":"2023-03-26T21:05:05.262245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# create datasets","metadata":{"id":"FpGqTHp1qoLC","outputId":"a4796bda-5c20-491f-effd-9f80d9d7964c","execution":{"iopub.status.busy":"2023-03-26T00:15:15.661901Z","iopub.execute_input":"2023-03-26T00:15:15.662484Z","iopub.status.idle":"2023-03-26T00:15:15.672053Z","shell.execute_reply.started":"2023-03-26T00:15:15.662447Z","shell.execute_reply":"2023-03-26T00:15:15.670658Z"}}},{"cell_type":"code","source":"# Load your own corpus\ndef load_custom_corpus(file_path):\n    import pandas as pd\n    df = pd.read_csv(file_path)\n    df = df.fillna('')\n    df = df[df['data_type'] == 'unknown'] # only take rows that do not belong to train/dev/test of IFD-EN-5203\n    sentences = [sent for sent in df['text']]\n    return {'text': sentences}\n\ndef tokenize_function(examples):\n    return tokenizer((examples['text']), truncation=True, max_length=128, padding='max_length')\n\nfile_path_en = '/kaggle/input/dit-thesis-datasets/datasets_kaggle/English/Incels.is/IFC-22-EN_updated.csv'  # Replace this with the path to your corpus file\ncorpus_en = load_custom_corpus(file_path_en)\ndataset_en = Dataset.from_dict(corpus_en)\ntokenized_dataset_en = dataset_en.map(tokenize_function, batched=True, remove_columns=['text'])\n\nfile_path_it = '/kaggle/input/dit-thesis-datasets/datasets_kaggle/Italian/Il_forum_dei_brutti/IFC-22-IT_updated.csv'  # Replace this with the path to your corpus file\ncorpus_it = load_custom_corpus(file_path_it)\ndataset_it = Dataset.from_dict(corpus_it)\ntokenized_dataset_it = dataset_it.map(tokenize_function, batched=True, remove_columns=['text'])\nprint(tokenized_dataset_en)\nprint(tokenized_dataset_it)","metadata":{"id":"FpGqTHp1qoLC","outputId":"a4796bda-5c20-491f-effd-9f80d9d7964c","execution":{"iopub.status.busy":"2023-03-26T19:12:25.256809Z","iopub.execute_input":"2023-03-26T19:12:25.257360Z","iopub.status.idle":"2023-03-26T19:31:13.677709Z","shell.execute_reply.started":"2023-03-26T19:12:25.257316Z","shell.execute_reply":"2023-03-26T19:31:13.676469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# create pickles","metadata":{}},{"cell_type":"code","source":"# path_dataset_en = '/kaggle/working/'\n# filename_pickle_en = 'IFC-22-EN_'+str(int(len(tokenized_dataset_en)/1000))+'k.pickle'\n# path_pickle_en = os.path.join(path_dataset_en,filename_pickle_en)\n\n# if not os.path.isfile(path_pickle_en):\n#     # Save the tokenized_dataset as a pickle file\n#     with open(path_pickle_en, 'wb') as file:\n#         pickle.dump(tokenized_dataset_en, file)\n# else:\n#     print(f\"{path_pickle_en} already exists. Not overwriting.\")\n\n# path_dataset_it = '/kaggle/working/'\n# filename_pickle_it = 'IFC-22-IT_'+str(int(len(tokenized_dataset_it)/1000))+'k.pickle'\n# path_pickle_it = os.path.join(path_dataset_it,filename_pickle_it)\n\n# if not os.path.isfile(path_pickle_it):\n#     # Save the tokenized_dataset as a pickle file\n#     with open(path_pickle_it, 'wb') as file:\n#         pickle.dump(tokenized_dataset_it, file)\n# else:\n#     print(f\"{path_pickle_it} already exists. Not overwriting.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# shuffle and sample datasets\n\n# # Set a seed to ensure reproducibility when shuffling\n# seed = 42\n# sample_n_list = [5_000, 10_000, 50_000, 100_000, 500_000]\n\n# for sample_n in sample_n_list:\n#     shuffled_dataset_en = tokenized_dataset_en.shuffle(seed=seed)\n#     sampled_dataset_en = shuffled_dataset_en.select(range(sample_n))\n#     print(sampled_dataset_en)\n\n#     shuffled_dataset_it = tokenized_dataset_it.shuffle(seed=seed)\n#     sampled_dataset_it = shuffled_dataset_it.select(range(sample_n))\n#     print(sampled_dataset_it)\n\n#     path_dataset_en = '/home/pgajo/working/data/datasets/English/Incels.is'\n#     filename_pickle_en = 'IFC-22-EN_'+str(int(sample_n/1000))+'k.pickle'\n#     path_pickle_en = os.path.join(path_dataset_en,filename_pickle_en)\n\n#     if not os.path.isfile(path_pickle_en):\n#         # Save the tokenized_dataset as a pickle file\n#         with open(path_pickle_en, 'wb') as file:\n#             pickle.dump(sampled_dataset_en, file)\n#     else:\n#         print(f\"{path_pickle_en} already exists. Not overwriting.\")\n\n#     path_dataset_it = '/home/pgajo/working/data/datasets/Italian/Il_forum_dei_brutti'\n#     filename_pickle_it = 'IFC-22-IT_'+str(int(sample_n/1000))+'k.pickle'\n#     path_pickle_it = os.path.join(path_dataset_it,filename_pickle_it)\n\n#     if not os.path.isfile(path_pickle_it):\n#         # Save the tokenized_dataset as a pickle file\n#         with open(path_pickle_it, 'wb') as file:\n#             pickle.dump(sampled_dataset_it, file)\n#     else:\n#         print(f\"{path_pickle_it} already exists. Not overwriting.\")","metadata":{"id":"FpGqTHp1qoLC","outputId":"a4796bda-5c20-491f-effd-9f80d9d7964c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # load pickles\n\n# path_pickle_en = '/kaggle/input/dit-thesis-datasets/datasets_kaggle/English/Incels.is/IFC-22-EN_4752k.pickle'\n\n# # Load the tokenized_dataset from the pickle file\n# with open(path_pickle_en, 'rb') as file:\n#     tokenized_dataset_en = pickle.load(file)\n\n# path_pickle_it = '/kaggle/input/dit-thesis-datasets/datasets_kaggle/Italian/Il_forum_dei_brutti/IFC-22-IT_627k.pickle'\n\n# # Load the tokenized_dataset from the pickle file\n# with open(path_pickle_it, 'rb') as file:\n#     tokenized_dataset_it = pickle.load(file)\n    \n# print(tokenized_dataset_en)\n# print(tokenized_dataset_it)","metadata":{"id":"FpGqTHp1qoLC","outputId":"a4796bda-5c20-491f-effd-9f80d9d7964c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# shuffle and sample datasets\n\n# Set a seed to ensure reproducibility when shuffling\nseed = 42\n\nfrom datasets import concatenate_datasets\n\nif language_option == 'multi':\n    shuffled_dataset_en = tokenized_dataset_en.shuffle(seed=seed)\n    sampled_dataset_en = shuffled_dataset_en.select(range(sample_n))\n    print('sampled_dataset_en\\n',sampled_dataset_en)\n\n    shuffled_dataset_it = tokenized_dataset_it.shuffle(seed=seed)\n    sampled_dataset_it = shuffled_dataset_it.select(range(sample_n))\n    print('sampled_dataset_it\\n', sampled_dataset_it)\n\n    # Assuming you have loaded the two datasets as `dataset1` and `dataset2`\n    merged_dataset = concatenate_datasets([sampled_dataset_en, sampled_dataset_it])\n    train_dataset = merged_dataset.shuffle(seed=seed)\n    print('train_dataset_multi\\n', train_dataset)\n    \nif language_option == 'english':\n    \n    shuffled_dataset_en = tokenized_dataset_en.shuffle(seed=seed)\n    train_dataset = shuffled_dataset_en.select(range(sample_n))\n    print('train_dataset_en\\n', train_dataset)\n    \nif language_option == 'italian':\n    \n    shuffled_dataset_it = tokenized_dataset_it.shuffle(seed=seed)\n    train_dataset = shuffled_dataset_it.select(range(sample_n))\n    print('train_dataset_it\\n', train_dataset)","metadata":{"execution":{"iopub.status.busy":"2023-03-26T19:34:58.164077Z","iopub.execute_input":"2023-03-26T19:34:58.164507Z","iopub.status.idle":"2023-03-26T19:34:59.418088Z","shell.execute_reply.started":"2023-03-26T19:34:58.164446Z","shell.execute_reply":"2023-03-26T19:34:59.416840Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=True, mlm_probability=0.15)\n\nmodel = AutoModelForMaskedLM.from_pretrained(model_name)\n\ntraining_args = TrainingArguments(\n    output_dir='/kaggle/working/results/',\n    num_train_epochs=1,\n    per_device_train_batch_size=32,\n    save_steps=10_000,\n    save_total_limit=2,\n    logging_dir='/kaggle/working/logs/',\n    logging_steps=100,\n    report_to='none',\n    disable_tqdm=False,\n)\n\n# extend the huggingface Trainer class to make custom methods\nclass CustomTrainer(Trainer):\n    def log(self, logs: Dict[str, float]):\n        # Call the original `log` method to preserve its functionality\n        super().log(logs)\n\n        # Calculate total steps\n        total_steps = len(self.train_dataset) * self.args.num_train_epochs // self.args.per_device_train_batch_size\n        if self.args.world_size > 1:\n            total_steps = total_steps // self.args.world_size\n\n        # Calculate the percentage of completed steps\n        progress_percentage = 100 * self.state.global_step / total_steps\n\n        # Print the custom message\n        print(\"Global step:\", self.state.global_step)\n        print(f\"MOM LOOK I'M LOGGING: {progress_percentage:.2f}% steps completed ({self.state.global_step}/{total_steps})\")\n\ntrainer = CustomTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n)\n\n\ntrainer.train(\n    # resume_from_checkpoint = True\n    )","metadata":{"execution":{"iopub.status.busy":"2023-03-26T19:35:07.234046Z","iopub.execute_input":"2023-03-26T19:35:07.234513Z","iopub.status.idle":"2023-03-26T19:36:06.243994Z","shell.execute_reply.started":"2023-03-26T19:35:07.234433Z","shell.execute_reply":"2023-03-26T19:36:06.242499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save_pretrained(model_path)\ntokenizer.save_pretrained(model_path)","metadata":{"execution":{"iopub.status.busy":"2023-03-26T17:18:19.220874Z","iopub.status.idle":"2023-03-26T17:18:19.222079Z","shell.execute_reply.started":"2023-03-26T17:18:19.221785Z","shell.execute_reply":"2023-03-26T17:18:19.221813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}