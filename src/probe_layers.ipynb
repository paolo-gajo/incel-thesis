{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████| 3156/3156 [01:32<00:00, 34.07it/s]\n",
      "Training and Evaluating:   0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of embeddings for layer 1: (3156, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training and Evaluating:   8%|▊         | 1/12 [00:00<00:07,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1: F1 Score = 0.2706766917293233, Accuracy = 0.8465189873417721\n",
      "Shape of embeddings for layer 2: (3156, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training and Evaluating:  17%|█▋        | 2/12 [00:01<00:07,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 2: F1 Score = 0.4102564102564103, Accuracy = 0.8544303797468354\n",
      "Shape of embeddings for layer 3: (3156, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training and Evaluating:  25%|██▌       | 3/12 [00:02<00:06,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 3: F1 Score = 0.47852760736196326, Accuracy = 0.865506329113924\n",
      "Shape of embeddings for layer 4: (3156, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training and Evaluating:  33%|███▎      | 4/12 [00:03<00:06,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 4: F1 Score = 0.5841584158415841, Accuracy = 0.8670886075949367\n",
      "Shape of embeddings for layer 5: (3156, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training and Evaluating:  42%|████▏     | 5/12 [00:04<00:06,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 5: F1 Score = 0.5853658536585367, Accuracy = 0.865506329113924\n",
      "Shape of embeddings for layer 6: (3156, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training and Evaluating:  50%|█████     | 6/12 [00:05<00:05,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 6: F1 Score = 0.5170731707317073, Accuracy = 0.8433544303797469\n",
      "Shape of embeddings for layer 7: (3156, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training and Evaluating:  58%|█████▊    | 7/12 [00:06<00:04,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 7: F1 Score = 0.5226130653266331, Accuracy = 0.8496835443037974\n",
      "Shape of embeddings for layer 8: (3156, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training and Evaluating:  67%|██████▋   | 8/12 [00:07<00:03,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 8: F1 Score = 0.5743589743589744, Accuracy = 0.8686708860759493\n",
      "Shape of embeddings for layer 9: (3156, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training and Evaluating:  75%|███████▌  | 9/12 [00:08<00:02,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 9: F1 Score = 0.5263157894736843, Accuracy = 0.8575949367088608\n",
      "Shape of embeddings for layer 10: (3156, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training and Evaluating:  83%|████████▎ | 10/12 [00:08<00:01,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 10: F1 Score = 0.5, Accuracy = 0.8322784810126582\n",
      "Shape of embeddings for layer 11: (3156, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training and Evaluating:  92%|█████████▏| 11/12 [00:09<00:00,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 11: F1 Score = 0.47000000000000003, Accuracy = 0.8322784810126582\n",
      "Shape of embeddings for layer 12: (3156, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training and Evaluating: 100%|██████████| 12/12 [00:10<00:00,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 12: F1 Score = 0.5148514851485148, Accuracy = 0.8449367088607594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize an empty DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['Layer', 'F1_Score', 'Accuracy'])\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('/home/pgajo/working/incels/data/datasets/English/Incels.is/IFD-EN-5203.csv',\n",
    "                #  nrows=100\n",
    "                 )\n",
    "# Filter the dataset\n",
    "df = df[df['incel_terms'] == 0]\n",
    "\n",
    "# Initialize BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states=True)\n",
    "\n",
    "# Function to get [CLS] token embeddings for all layers\n",
    "def get_cls_embeddings(sentence, model, tokenizer):\n",
    "    tokens = tokenizer(sentence, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokens)\n",
    "    hidden_states = outputs.hidden_states\n",
    "    cls_embeddings = [layer[:, 0, :].numpy() for layer in hidden_states[1:]]  # Skip the embedding layer\n",
    "    return cls_embeddings\n",
    "\n",
    "# Initialize a list of lists to store embeddings for all samples for each layer\n",
    "all_layer_embeddings = [[] for _ in range(12)]\n",
    "\n",
    "# Adding tqdm for progress tracking during extraction\n",
    "for text in tqdm(df['text'], desc=\"Extracting embeddings\"):\n",
    "    cls_embeddings = get_cls_embeddings(text, model, tokenizer)\n",
    "    for i, emb in enumerate(cls_embeddings):\n",
    "        all_layer_embeddings[i].append(emb)\n",
    "\n",
    "# Convert list of lists of arrays to a list of 2D numpy arrays\n",
    "all_layer_embeddings = [np.vstack(layer) for layer in all_layer_embeddings]\n",
    "\n",
    "# Prepare labels\n",
    "labels = df['hs'].values\n",
    "\n",
    "# Adding tqdm for progress tracking during training and evaluation\n",
    "for i, embeddings in enumerate(tqdm(all_layer_embeddings, desc=\"Training and Evaluating\")):\n",
    "    print(f\"Shape of embeddings for layer {i+1}: {embeddings.shape}\")  # Debugging line\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(embeddings, labels, test_size=0.2, random_state=42)\n",
    "    clf = LogisticRegression(max_iter=1000)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Layer {i+1}: F1 Score = {f1}, Accuracy = {acc}\")\n",
    "\n",
    "    # Append the results to the DataFrame\n",
    "    results_df = results_df.append({'Layer': i+1, 'F1_Score': f1, 'Accuracy': acc}, ignore_index=True)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_df.to_csv('/home/pgajo/working/incels/results/bert_layer_probing/layerwise_evaluation_metrics_NOincel_terms.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pgajo-Fz_qUQZq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
