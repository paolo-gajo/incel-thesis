{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dataframe:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_f1</th>\n",
       "      <th>val_precision</th>\n",
       "      <th>val_recall</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>model</th>\n",
       "      <th>train_len</th>\n",
       "      <th>train_set(s)</th>\n",
       "      <th>dev_set(s)</th>\n",
       "      <th>test_set(s)</th>\n",
       "      <th>run_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5350492192072827</td>\n",
       "      <td>0.4128927445153192</td>\n",
       "      <td>0.7958271236959761</td>\n",
       "      <td>0.752112676056338</td>\n",
       "      <td>0.7958271236959761</td>\n",
       "      <td>0.6236578554380685</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6470588235294118</td>\n",
       "      <td>0.7</td>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>3642</td>\n",
       "      <td>train_incelsis(3642)</td>\n",
       "      <td>dev_incelsis(780)</td>\n",
       "      <td>test_fdb_250(250)</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.3384101656204286</td>\n",
       "      <td>0.4675384321943762</td>\n",
       "      <td>0.8372093023255814</td>\n",
       "      <td>0.8811188811188811</td>\n",
       "      <td>0.8372093023255814</td>\n",
       "      <td>0.9518080197449308</td>\n",
       "      <td>0.6242774566473989</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.6242774566473989</td>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>3642</td>\n",
       "      <td>train_incelsis(3642)</td>\n",
       "      <td>dev_incelsis(780)</td>\n",
       "      <td>test_fdb_250(250)</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.3023153563426284</td>\n",
       "      <td>0.4656150373202578</td>\n",
       "      <td>0.8567026194144838</td>\n",
       "      <td>0.8348348348348348</td>\n",
       "      <td>0.8567026194144838</td>\n",
       "      <td>1.006554617662914</td>\n",
       "      <td>0.7000000000000001</td>\n",
       "      <td>0.7070707070707071</td>\n",
       "      <td>0.7000000000000001</td>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>3642</td>\n",
       "      <td>train_incelsis(3642)</td>\n",
       "      <td>dev_incelsis(780)</td>\n",
       "      <td>test_fdb_250(250)</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2403215408619297</td>\n",
       "      <td>0.5071578850584789</td>\n",
       "      <td>0.858034321372855</td>\n",
       "      <td>0.8461538461538461</td>\n",
       "      <td>0.858034321372855</td>\n",
       "      <td>1.132825470529497</td>\n",
       "      <td>0.7029702970297029</td>\n",
       "      <td>0.7029702970297029</td>\n",
       "      <td>0.7029702970297029</td>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>3642</td>\n",
       "      <td>train_incelsis(3642)</td>\n",
       "      <td>dev_incelsis(780)</td>\n",
       "      <td>test_fdb_250(250)</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>epoch</td>\n",
       "      <td>train_loss</td>\n",
       "      <td>val_loss</td>\n",
       "      <td>val_f1</td>\n",
       "      <td>val_precision</td>\n",
       "      <td>val_recall</td>\n",
       "      <td>test_loss</td>\n",
       "      <td>test_f1</td>\n",
       "      <td>test_precision</td>\n",
       "      <td>test_recall</td>\n",
       "      <td>model</td>\n",
       "      <td>train_len</td>\n",
       "      <td>train_set(s)</td>\n",
       "      <td>dev_set(s)</td>\n",
       "      <td>test_set(s)</td>\n",
       "      <td>run_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5000550539446623</td>\n",
       "      <td>0.4414559196186613</td>\n",
       "      <td>0.7262357414448669</td>\n",
       "      <td>0.9095238095238096</td>\n",
       "      <td>0.7262357414448669</td>\n",
       "      <td>0.7749955840408802</td>\n",
       "      <td>0.3555555555555555</td>\n",
       "      <td>0.7058823529411765</td>\n",
       "      <td>0.3555555555555555</td>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>12642</td>\n",
       "      <td>train_hateval_2019_english(9000)\\ntrain_incels...</td>\n",
       "      <td>dev_incelsis(780)</td>\n",
       "      <td>test_fdb_250(250)</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.3797231305645075</td>\n",
       "      <td>0.3080979939455128</td>\n",
       "      <td>0.8488745980707396</td>\n",
       "      <td>0.8627450980392157</td>\n",
       "      <td>0.8488745980707396</td>\n",
       "      <td>0.6303297209087759</td>\n",
       "      <td>0.6741573033707866</td>\n",
       "      <td>0.7792207792207793</td>\n",
       "      <td>0.6741573033707866</td>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>12642</td>\n",
       "      <td>train_hateval_2019_english(9000)\\ntrain_incels...</td>\n",
       "      <td>dev_incelsis(780)</td>\n",
       "      <td>test_fdb_250(250)</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.3181278575447392</td>\n",
       "      <td>0.360476545015426</td>\n",
       "      <td>0.8651162790697674</td>\n",
       "      <td>0.8480243161094225</td>\n",
       "      <td>0.8651162790697674</td>\n",
       "      <td>0.7809389565663878</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.7252747252747253</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>12642</td>\n",
       "      <td>train_hateval_2019_english(9000)\\ntrain_incels...</td>\n",
       "      <td>dev_incelsis(780)</td>\n",
       "      <td>test_fdb_250(250)</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2887145595677028</td>\n",
       "      <td>0.4677662092714798</td>\n",
       "      <td>0.8629921259842519</td>\n",
       "      <td>0.8589341692789969</td>\n",
       "      <td>0.8629921259842519</td>\n",
       "      <td>1.0896175909874728</td>\n",
       "      <td>0.6737967914438502</td>\n",
       "      <td>0.7325581395348837</td>\n",
       "      <td>0.6737967914438502</td>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>12642</td>\n",
       "      <td>train_hateval_2019_english(9000)\\ntrain_incels...</td>\n",
       "      <td>dev_incelsis(780)</td>\n",
       "      <td>test_fdb_250(250)</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>epoch</td>\n",
       "      <td>train_loss</td>\n",
       "      <td>val_loss</td>\n",
       "      <td>val_f1</td>\n",
       "      <td>val_precision</td>\n",
       "      <td>val_recall</td>\n",
       "      <td>test_loss</td>\n",
       "      <td>test_f1</td>\n",
       "      <td>test_precision</td>\n",
       "      <td>test_recall</td>\n",
       "      <td>model</td>\n",
       "      <td>train_len</td>\n",
       "      <td>train_set(s)</td>\n",
       "      <td>dev_set(s)</td>\n",
       "      <td>test_set(s)</td>\n",
       "      <td>run_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5289484620101618</td>\n",
       "      <td>0.4541001937979338</td>\n",
       "      <td>0.7824933687002652</td>\n",
       "      <td>0.6735159817351598</td>\n",
       "      <td>0.7824933687002652</td>\n",
       "      <td>0.5597202363424003</td>\n",
       "      <td>0.6995515695067265</td>\n",
       "      <td>0.639344262295082</td>\n",
       "      <td>0.6995515695067265</td>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>8142</td>\n",
       "      <td>train_hateval_2019_spanish(4500)\\ntrain_incels...</td>\n",
       "      <td>dev_incelsis(780)</td>\n",
       "      <td>test_fdb_250(250)</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.3726204961230923</td>\n",
       "      <td>0.3374316740819082</td>\n",
       "      <td>0.8558282208588956</td>\n",
       "      <td>0.8303571428571429</td>\n",
       "      <td>0.8558282208588956</td>\n",
       "      <td>0.7375891570700333</td>\n",
       "      <td>0.6551724137931033</td>\n",
       "      <td>0.7808219178082192</td>\n",
       "      <td>0.6551724137931033</td>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>8142</td>\n",
       "      <td>train_hateval_2019_spanish(4500)\\ntrain_incels...</td>\n",
       "      <td>dev_incelsis(780)</td>\n",
       "      <td>test_fdb_250(250)</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.3270026911832282</td>\n",
       "      <td>0.5027257889528207</td>\n",
       "      <td>0.8562783661119516</td>\n",
       "      <td>0.8202898550724638</td>\n",
       "      <td>0.8562783661119516</td>\n",
       "      <td>0.9893020022354904</td>\n",
       "      <td>0.6551724137931033</td>\n",
       "      <td>0.7808219178082192</td>\n",
       "      <td>0.6551724137931033</td>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>8142</td>\n",
       "      <td>train_hateval_2019_spanish(4500)\\ntrain_incels...</td>\n",
       "      <td>dev_incelsis(780)</td>\n",
       "      <td>test_fdb_250(250)</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2694933175090801</td>\n",
       "      <td>0.5456155501519881</td>\n",
       "      <td>0.8588957055214723</td>\n",
       "      <td>0.8333333333333334</td>\n",
       "      <td>0.8588957055214723</td>\n",
       "      <td>1.2281266682693968</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.7567567567567568</td>\n",
       "      <td>0.64</td>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>8142</td>\n",
       "      <td>train_hateval_2019_spanish(4500)\\ntrain_incels...</td>\n",
       "      <td>dev_incelsis(780)</td>\n",
       "      <td>test_fdb_250(250)</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>epoch</td>\n",
       "      <td>train_loss</td>\n",
       "      <td>val_loss</td>\n",
       "      <td>val_f1</td>\n",
       "      <td>val_precision</td>\n",
       "      <td>val_recall</td>\n",
       "      <td>test_loss</td>\n",
       "      <td>test_f1</td>\n",
       "      <td>test_precision</td>\n",
       "      <td>test_recall</td>\n",
       "      <td>model</td>\n",
       "      <td>train_len</td>\n",
       "      <td>train_set(s)</td>\n",
       "      <td>dev_set(s)</td>\n",
       "      <td>test_set(s)</td>\n",
       "      <td>run_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5106592688012418</td>\n",
       "      <td>0.3460708924246077</td>\n",
       "      <td>0.7987220447284344</td>\n",
       "      <td>0.8064516129032258</td>\n",
       "      <td>0.7987220447284344</td>\n",
       "      <td>0.5447680212091655</td>\n",
       "      <td>0.6404494382022472</td>\n",
       "      <td>0.7402597402597403</td>\n",
       "      <td>0.6404494382022472</td>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>17142</td>\n",
       "      <td>train_hateval_2019_english(9000)\\ntrain_hateva...</td>\n",
       "      <td>dev_incelsis(780)</td>\n",
       "      <td>test_fdb_250(250)</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.3840005866187132</td>\n",
       "      <td>0.316858457895566</td>\n",
       "      <td>0.8377581120943953</td>\n",
       "      <td>0.7845303867403315</td>\n",
       "      <td>0.8377581120943953</td>\n",
       "      <td>0.5041381004266441</td>\n",
       "      <td>0.7113402061855671</td>\n",
       "      <td>0.7419354838709677</td>\n",
       "      <td>0.7113402061855671</td>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>17142</td>\n",
       "      <td>train_hateval_2019_english(9000)\\ntrain_hateva...</td>\n",
       "      <td>dev_incelsis(780)</td>\n",
       "      <td>test_fdb_250(250)</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.3238812555490314</td>\n",
       "      <td>0.4055484937627476</td>\n",
       "      <td>0.8390092879256966</td>\n",
       "      <td>0.8212121212121212</td>\n",
       "      <td>0.8390092879256966</td>\n",
       "      <td>0.7497049808735028</td>\n",
       "      <td>0.7065217391304347</td>\n",
       "      <td>0.7831325301204819</td>\n",
       "      <td>0.7065217391304347</td>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>17142</td>\n",
       "      <td>train_hateval_2019_english(9000)\\ntrain_hateva...</td>\n",
       "      <td>dev_incelsis(780)</td>\n",
       "      <td>test_fdb_250(250)</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2833429005041994</td>\n",
       "      <td>0.5293764906676429</td>\n",
       "      <td>0.8346213292117465</td>\n",
       "      <td>0.8157099697885196</td>\n",
       "      <td>0.8346213292117465</td>\n",
       "      <td>1.059381509636296</td>\n",
       "      <td>0.7243243243243244</td>\n",
       "      <td>0.7976190476190477</td>\n",
       "      <td>0.7243243243243244</td>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>17142</td>\n",
       "      <td>train_hateval_2019_english(9000)\\ntrain_hateva...</td>\n",
       "      <td>dev_incelsis(780)</td>\n",
       "      <td>test_fdb_250(250)</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch          train_loss            val_loss              val_f1  \\\n",
       "0     1.0  0.5350492192072827  0.4128927445153192  0.7958271236959761   \n",
       "1     2.0  0.3384101656204286  0.4675384321943762  0.8372093023255814   \n",
       "2     3.0  0.3023153563426284  0.4656150373202578  0.8567026194144838   \n",
       "3     4.0  0.2403215408619297  0.5071578850584789   0.858034321372855   \n",
       "4   epoch          train_loss            val_loss              val_f1   \n",
       "5     1.0  0.5000550539446623  0.4414559196186613  0.7262357414448669   \n",
       "6     2.0  0.3797231305645075  0.3080979939455128  0.8488745980707396   \n",
       "7     3.0  0.3181278575447392   0.360476545015426  0.8651162790697674   \n",
       "8     4.0  0.2887145595677028  0.4677662092714798  0.8629921259842519   \n",
       "9   epoch          train_loss            val_loss              val_f1   \n",
       "10    1.0  0.5289484620101618  0.4541001937979338  0.7824933687002652   \n",
       "11    2.0  0.3726204961230923  0.3374316740819082  0.8558282208588956   \n",
       "12    3.0  0.3270026911832282  0.5027257889528207  0.8562783661119516   \n",
       "13    4.0  0.2694933175090801  0.5456155501519881  0.8588957055214723   \n",
       "14  epoch          train_loss            val_loss              val_f1   \n",
       "15    1.0  0.5106592688012418  0.3460708924246077  0.7987220447284344   \n",
       "16    2.0  0.3840005866187132   0.316858457895566  0.8377581120943953   \n",
       "17    3.0  0.3238812555490314  0.4055484937627476  0.8390092879256966   \n",
       "18    4.0  0.2833429005041994  0.5293764906676429  0.8346213292117465   \n",
       "\n",
       "         val_precision          val_recall           test_loss  \\\n",
       "0    0.752112676056338  0.7958271236959761  0.6236578554380685   \n",
       "1   0.8811188811188811  0.8372093023255814  0.9518080197449308   \n",
       "2   0.8348348348348348  0.8567026194144838   1.006554617662914   \n",
       "3   0.8461538461538461   0.858034321372855   1.132825470529497   \n",
       "4        val_precision          val_recall           test_loss   \n",
       "5   0.9095238095238096  0.7262357414448669  0.7749955840408802   \n",
       "6   0.8627450980392157  0.8488745980707396  0.6303297209087759   \n",
       "7   0.8480243161094225  0.8651162790697674  0.7809389565663878   \n",
       "8   0.8589341692789969  0.8629921259842519  1.0896175909874728   \n",
       "9        val_precision          val_recall           test_loss   \n",
       "10  0.6735159817351598  0.7824933687002652  0.5597202363424003   \n",
       "11  0.8303571428571429  0.8558282208588956  0.7375891570700333   \n",
       "12  0.8202898550724638  0.8562783661119516  0.9893020022354904   \n",
       "13  0.8333333333333334  0.8588957055214723  1.2281266682693968   \n",
       "14       val_precision          val_recall           test_loss   \n",
       "15  0.8064516129032258  0.7987220447284344  0.5447680212091655   \n",
       "16  0.7845303867403315  0.8377581120943953  0.5041381004266441   \n",
       "17  0.8212121212121212  0.8390092879256966  0.7497049808735028   \n",
       "18  0.8157099697885196  0.8346213292117465   1.059381509636296   \n",
       "\n",
       "               test_f1      test_precision         test_recall  \\\n",
       "0                  0.7  0.6470588235294118                 0.7   \n",
       "1   0.6242774566473989                0.75  0.6242774566473989   \n",
       "2   0.7000000000000001  0.7070707070707071  0.7000000000000001   \n",
       "3   0.7029702970297029  0.7029702970297029  0.7029702970297029   \n",
       "4              test_f1      test_precision         test_recall   \n",
       "5   0.3555555555555555  0.7058823529411765  0.3555555555555555   \n",
       "6   0.6741573033707866  0.7792207792207793  0.6741573033707866   \n",
       "7               0.6875  0.7252747252747253              0.6875   \n",
       "8   0.6737967914438502  0.7325581395348837  0.6737967914438502   \n",
       "9              test_f1      test_precision         test_recall   \n",
       "10  0.6995515695067265   0.639344262295082  0.6995515695067265   \n",
       "11  0.6551724137931033  0.7808219178082192  0.6551724137931033   \n",
       "12  0.6551724137931033  0.7808219178082192  0.6551724137931033   \n",
       "13                0.64  0.7567567567567568                0.64   \n",
       "14             test_f1      test_precision         test_recall   \n",
       "15  0.6404494382022472  0.7402597402597403  0.6404494382022472   \n",
       "16  0.7113402061855671  0.7419354838709677  0.7113402061855671   \n",
       "17  0.7065217391304347  0.7831325301204819  0.7065217391304347   \n",
       "18  0.7243243243243244  0.7976190476190477  0.7243243243243244   \n",
       "\n",
       "               model  train_len  \\\n",
       "0   xlm-roberta-base       3642   \n",
       "1   xlm-roberta-base       3642   \n",
       "2   xlm-roberta-base       3642   \n",
       "3   xlm-roberta-base       3642   \n",
       "4              model  train_len   \n",
       "5   xlm-roberta-base      12642   \n",
       "6   xlm-roberta-base      12642   \n",
       "7   xlm-roberta-base      12642   \n",
       "8   xlm-roberta-base      12642   \n",
       "9              model  train_len   \n",
       "10  xlm-roberta-base       8142   \n",
       "11  xlm-roberta-base       8142   \n",
       "12  xlm-roberta-base       8142   \n",
       "13  xlm-roberta-base       8142   \n",
       "14             model  train_len   \n",
       "15  xlm-roberta-base      17142   \n",
       "16  xlm-roberta-base      17142   \n",
       "17  xlm-roberta-base      17142   \n",
       "18  xlm-roberta-base      17142   \n",
       "\n",
       "                                         train_set(s)         dev_set(s)  \\\n",
       "0                                train_incelsis(3642)  dev_incelsis(780)   \n",
       "1                                train_incelsis(3642)  dev_incelsis(780)   \n",
       "2                                train_incelsis(3642)  dev_incelsis(780)   \n",
       "3                                train_incelsis(3642)  dev_incelsis(780)   \n",
       "4                                        train_set(s)         dev_set(s)   \n",
       "5   train_hateval_2019_english(9000)\\ntrain_incels...  dev_incelsis(780)   \n",
       "6   train_hateval_2019_english(9000)\\ntrain_incels...  dev_incelsis(780)   \n",
       "7   train_hateval_2019_english(9000)\\ntrain_incels...  dev_incelsis(780)   \n",
       "8   train_hateval_2019_english(9000)\\ntrain_incels...  dev_incelsis(780)   \n",
       "9                                        train_set(s)         dev_set(s)   \n",
       "10  train_hateval_2019_spanish(4500)\\ntrain_incels...  dev_incelsis(780)   \n",
       "11  train_hateval_2019_spanish(4500)\\ntrain_incels...  dev_incelsis(780)   \n",
       "12  train_hateval_2019_spanish(4500)\\ntrain_incels...  dev_incelsis(780)   \n",
       "13  train_hateval_2019_spanish(4500)\\ntrain_incels...  dev_incelsis(780)   \n",
       "14                                       train_set(s)         dev_set(s)   \n",
       "15  train_hateval_2019_english(9000)\\ntrain_hateva...  dev_incelsis(780)   \n",
       "16  train_hateval_2019_english(9000)\\ntrain_hateva...  dev_incelsis(780)   \n",
       "17  train_hateval_2019_english(9000)\\ntrain_hateva...  dev_incelsis(780)   \n",
       "18  train_hateval_2019_english(9000)\\ntrain_hateva...  dev_incelsis(780)   \n",
       "\n",
       "          test_set(s)  run_id  \n",
       "0   test_fdb_250(250)      17  \n",
       "1   test_fdb_250(250)      17  \n",
       "2   test_fdb_250(250)      17  \n",
       "3   test_fdb_250(250)      17  \n",
       "4         test_set(s)  run_id  \n",
       "5   test_fdb_250(250)      18  \n",
       "6   test_fdb_250(250)      18  \n",
       "7   test_fdb_250(250)      18  \n",
       "8   test_fdb_250(250)      18  \n",
       "9         test_set(s)  run_id  \n",
       "10  test_fdb_250(250)      19  \n",
       "11  test_fdb_250(250)      19  \n",
       "12  test_fdb_250(250)      19  \n",
       "13  test_fdb_250(250)      19  \n",
       "14        test_set(s)  run_id  \n",
       "15  test_fdb_250(250)      20  \n",
       "16  test_fdb_250(250)      20  \n",
       "17  test_fdb_250(250)      20  \n",
       "18  test_fdb_250(250)      20  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "# timestamp for file naming\n",
    "now = datetime.now()\n",
    "time_str = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "date_str = now.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Set the directory where the CSV files are located\n",
    "csv_dir = '/home/pgajo/working/data/metrics/metrics_multilingual/xlm-roberta-base'\n",
    "\n",
    "def merge_csv(csv_dir_path, repeat_header = False):\n",
    "    # Create an empty data frame\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # Create save path for the CSV file\n",
    "    save_path = os.path.join(csv_dir_path, date_str+'_'+os.listdir(csv_dir_path)[0][3:])\n",
    "\n",
    "    # Loop through the files in the directory\n",
    "    for filename in sorted(os.listdir(csv_dir_path)):\n",
    "        \n",
    "        if filename.endswith('.csv'):\n",
    "            # If the filename contains a numeral, read the CSV file into a temporary data frame\n",
    "            df_temp = pd.read_csv(os.path.join(csv_dir_path, filename))\n",
    "            if repeat_header:\n",
    "                # Append to csv the whole df each time, including the header\n",
    "                df_temp.to_csv(save_path, mode='a', index=False)\n",
    "            else:\n",
    "                # Concatenate the temporary data frame to the main data frame\n",
    "                df = pd.concat([df, df_temp]) # not to repeat header\n",
    "\n",
    "    if not repeat_header:\n",
    "        df.to_csv(save_path, mode='a', index=False)\n",
    "    print('Saved dataframe:')\n",
    "    display(pd.read_csv(save_path))\n",
    "\n",
    "merge_csv(csv_dir, repeat_header = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pgajo-Fz_qUQZq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
